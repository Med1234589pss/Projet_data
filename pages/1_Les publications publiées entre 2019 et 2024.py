import streamlit as st
import pandas as pd
import plotly.express as px
import matplotlib.pyplot as plt
from wordcloud import WordCloud

# Utiliser @st.cache_resource pour la mise en cache des donnÃ©es
@st.cache_resource
def load_data():
    return pd.read_csv('data/publications publiÃ©es entre 2019 et 2024.csv')

# Charger les donnÃ©es
df = load_data()

# Titre principal de la page
st.title("ğŸ“ˆ Visualisation des publications publiÃ©es entre 2019 et 2024")

# CrÃ©er deux colonnes : une pour le premier graphique et l'autre pour le filtre
col1, col2 = st.columns([3, 1])

with col2:
    # CrÃ©er un slider pour sÃ©lectionner la plage d'annÃ©es
    annees = st.select_slider('SÃ©lectionnez la plage d\'annÃ©es', options=list(range(2019, 2025)), value=(2019, 2024))

# Filtrer les donnÃ©es selon la plage d'annÃ©es sÃ©lectionnÃ©e
annee_debut, annee_fin = annees
df_filtered = df[(df['AnnÃ©e'] >= annee_debut) & (df['AnnÃ©e'] <= annee_fin)]

with col1:
    # Calcul de la rÃ©partition des types de publications aprÃ¨s le filtrage
    type_counts = df_filtered['Type'].value_counts().reset_index()
    type_counts.columns = ['Type', 'Nombre de publications']

    # CrÃ©ation du graphique avec Plotly
    fig1 = px.bar(type_counts, x='Type', y='Nombre de publications', 
                  title=f"RÃ©partition des types de publications ({annee_debut} - {annee_fin})",
                  labels={'Type': 'Type de publication', 'Nombre de publications': 'Nombre de publications'},
                  color='Type', color_discrete_sequence=px.colors.sequential.Viridis)

    # Affichage du premier graphique dans Streamlit
    st.plotly_chart(fig1)

# Calcul du cumul des publications par type et annÃ©e
df_grouped = df_filtered.groupby(['AnnÃ©e', 'Type']).size().reset_index(name='Nombre de publications')

# Calcul du cumul des publications par type
df_grouped['Nombre de publications cumulÃ©es'] = df_grouped.groupby('Type')['Nombre de publications'].cumsum()

# CrÃ©er deux colonnes pour afficher les graphiques cÃ´te Ã  cÃ´te
col3, col4 = st.columns([2, 1])

# Afficher le graphique cumulatif dans la premiÃ¨re colonne
with col3:
    st.subheader(f"Ã‰volution cumulÃ©e des publications de {annee_debut} Ã  {annee_fin}")
    fig2 = px.line(df_grouped, x="AnnÃ©e", y="Nombre de publications cumulÃ©es", color="Type", 
                   title=f"Ã‰volution cumulÃ©e des publications par type ({annee_debut} - {annee_fin})", 
                   labels={'AnnÃ©e': 'AnnÃ©e', 'Nombre de publications cumulÃ©es': 'Nombre de publications cumulÃ©es'})

    # Mettre Ã  jour les axes pour personnaliser les graduations
    fig2.update_xaxes(dtick=1, tickformat="%Y")

    # Affichage du graphique cumulatif dans Streamlit
    st.plotly_chart(fig2)

# Afficher le graphique en camembert de la rÃ©partition des langues dans la deuxiÃ¨me colonne
with col4:
    st.subheader("RÃ©partition des langues des publications")
    langue_counts = df_filtered['Langue'].value_counts()

    # CrÃ©ation du graphique en camembert (pie chart) avec Plotly
    fig3 = px.pie(langue_counts, names=langue_counts.index, values=langue_counts, 
                  title='RÃ©partition des langues des publications', 
                  color_discrete_sequence=px.colors.sequential.Plasma)

    # Affichage du graphique de rÃ©partition des langues
    st.plotly_chart(fig3)

# Assurez-vous que la colonne 'Date' est bien au format datetime
# Fonction pour traiter les diffÃ©rents formats de dates

def parse_date(date_str):
    if pd.isna(date_str):  # Si la valeur est NaN (NaT), la laisser telle quelle
        return pd.NaT
    
    # Si la valeur est dÃ©jÃ  un Timestamp (datetime), la laisser telle quelle
    if isinstance(date_str, pd.Timestamp):
        return date_str
    
    # VÃ©rifier si la date est une chaÃ®ne de caractÃ¨res avant de tenter de la traiter
    if isinstance(date_str, str):
        if len(date_str) == 4 and date_str.isdigit():  # Cas de l'annÃ©e seule
            return pd.to_datetime(date_str + "-01-01")
        
        # Si la date est au format annÃ©e-mois (exemple "2020-11"), ajouter le 1er jour du mois
        if len(date_str) == 7 and date_str[4] == '-' and date_str[:4].isdigit() and date_str[5:].isdigit():
            return pd.to_datetime(date_str + "-01")
        
        # Si la date est dÃ©jÃ  complÃ¨te (exemple "05/07/2022"), tenter de la convertir
        try:
            return pd.to_datetime(date_str, dayfirst=True)
        except:
            return pd.NaT  # Si la conversion Ã©choue, renvoyer NaT
    else:
        return pd.NaT  # Si ce n'est pas une chaÃ®ne ou un Timestamp valide, retourner NaT

# Appliquer la fonction Ã  la colonne 'Date'
df_filtered['Date'] = df_filtered['Date'].apply(parse_date)

# VÃ©rifier que la colonne 'Date' est correctement convertie en datetime
#if df_filtered['Date'].isnull().any():
 #   st.warning("Certaines dates sont mal formatÃ©es ou manquantes.")

# Ajouter une colonne 'AnnÃ©e' pour rÃ©fÃ©rence
df_filtered['AnnÃ©e'] = df_filtered['Date'].dt.year

# Interface Streamlit
st.title("Ã‰volution cumulÃ©e des publications par famille au fil du temps")
# **Filtre sur les familles**  
familles_uniques = df_filtered['Famille'].unique().tolist()
famille_selectionnee = st.multiselect(
    'SÃ©lectionnez les familles Ã  afficher :',
    options=familles_uniques,
    default=familles_uniques  # Par dÃ©faut, toutes les familles sont sÃ©lectionnÃ©es
)

# Appliquer le filtre sur les familles sÃ©lectionnÃ©es
if famille_selectionnee:
    df_filtered = df_filtered[df_filtered['Famille'].isin(famille_selectionnee)]

# Calculer le nombre de publications par famille et date
df_grouped_famille = df_filtered.groupby(['Date', 'Famille']).size().reset_index(name='Nombre de publications')

# Calculer le nombre de publications cumulÃ©es par famille
df_grouped_famille['Nombre de publications cumulÃ©es'] = df_grouped_famille.groupby('Famille')['Nombre de publications'].cumsum()

# CrÃ©er un graphique de l'Ã©volution cumulÃ©e des publications par famille
fig5 = px.line(
    df_grouped_famille, 
    x="Date",  # Utiliser la date pour l'axe X
    y="Nombre de publications cumulÃ©es",  # Nombre de publications cumulÃ©es pour l'axe Y
    color="Famille",  # SÃ©parer par famille
    title="Ã‰volution cumulÃ©e des publications par famille au fil du temps",
    labels={'Date': 'Date', 'Nombre de publications cumulÃ©es': 'Nombre de publications cumulÃ©es'}
)

# Personnalisation des axes
fig5.update_xaxes(
    tickformat="%Y-%m-%d",  # Afficher les dates au format AAAA-MM-JJ
    title="Date"
)

# Affichage du graphique cumulatif dans Streamlit
st.plotly_chart(fig5)

# Calcul de la rÃ©partition des publications par famille
famille_counts = df_filtered['Famille'].value_counts().reset_index()
famille_counts.columns = ['Famille', 'Nombre de publications']

# CrÃ©ation du graphique de rÃ©partition des publications par famille
fig4 = px.bar(famille_counts, x='Famille', y='Nombre de publications',
              title="RÃ©partition des publications par famille",
              labels={'Famille': 'Famille', 'Nombre de publications': 'Nombre de publications'},
              color='Famille', color_discrete_sequence=px.colors.sequential.Viridis)

# Affichage du graphique dans Streamlit
st.plotly_chart(fig4)

# ------------------------ Word Cloud ------------------------
st.subheader("ğŸŒ Nuage de mots (Word Cloud) des mots-clÃ©s")
# Extraire les mots-clÃ©s de la colonne 'Mots_clÃ©s' et les joindre en une seule chaÃ®ne
mots_cles = ' '.join(df['Mots_clÃ©s'].dropna().astype(str))

# CrÃ©er un WordCloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(mots_cles)

# Afficher le WordCloud avec matplotlib
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
st.pyplot(plt)

# ------------------------ Parallel Categories ------------------------
# Ajoutez une colonne 'size' avec les occurrences des combinaisons uniques
df_filtered['size'] = df_filtered.groupby(['Famille', 'Type', 'AnnÃ©e'])['Famille'].transform('count')

# CrÃ©ez un dictionnaire de couleurs pour chaque Famille
palette = px.colors.qualitative.Set2  # Palette de couleurs attrayante
unique_familles = df_filtered['Famille'].unique()
color_map = {famille: palette[i % len(palette)] for i, famille in enumerate(unique_familles)}

# Ajoutez une colonne 'color' correspondant Ã  la couleur de chaque 'Famille'
df_filtered['color'] = df_filtered['Famille'].map(color_map)

# CrÃ©ez le graphique avec des couleurs cohÃ©rentes
fig = px.parallel_categories(
    df_filtered,
    dimensions=['Famille', 'AnnÃ©e', 'Type'],
    color='color',  # Utilisez la colonne 'color' pour appliquer les couleurs
    color_continuous_scale=px.colors.sequential.Inferno
)

# Mise Ã  jour de la mise en page pour cacher la barre de couleur
fig.update_layout(
    title_text="Diagramme Parallel Categories : Famille â†’ Type â†’ AnnÃ©e",
    title_font=dict(size=18, color='rgb(0, 0, 0)', family='Arial, sans-serif'),  # Police du titre plus claire
    font=dict(size=14, color='rgb(0, 0, 0)', family='Arial, sans-serif'),  # Police des autres textes claire
    width=2000,  # Augmenter la largeur
    height=900,  # Augmenter la hauteur
    coloraxis_showscale=False,  # Cache l'Ã©chelle de couleur
    plot_bgcolor='rgb(255, 255, 255)',  # Fond blanc pour plus de clartÃ©
    paper_bgcolor='rgb(255, 255, 255)',  # Fond blanc de la page
    margin=dict(t=40, b=40, l=200, r=20)
)

# Afficher le graphique Parallel Categories dans Streamlit
st.plotly_chart(fig)

import pandas as pd
import plotly.express as px
import streamlit as st

# DÃ©finir la fonction pour analyser les dates
def parse_date(date_str):
    if pd.isna(date_str):  # Si la valeur est NaN (NaT), la laisser telle quelle
        return pd.NaT
    
    # Si la valeur est dÃ©jÃ  un Timestamp (datetime), la laisser telle quelle
    if isinstance(date_str, pd.Timestamp):
        return date_str
    
    # VÃ©rifier si la date est une chaÃ®ne de caractÃ¨res avant de tenter de la traiter
    if isinstance(date_str, str):
        if len(date_str) == 4 and date_str.isdigit():  # Cas de l'annÃ©e seule
            return pd.to_datetime(date_str + "-01-01")
        
        # Si la date est au format annÃ©e-mois (exemple "2020-11"), ajouter le 1er jour du mois
        if len(date_str) == 7 and date_str[4] == '-' and date_str[:4].isdigit() and date_str[5:].isdigit():
            return pd.to_datetime(date_str + "-01")
        
        # Si la date est dÃ©jÃ  complÃ¨te (exemple "05/07/2022"), tenter de la convertir
        try:
            return pd.to_datetime(date_str, dayfirst=True)
        except:
            return pd.NaT  # Si la conversion Ã©choue, renvoyer NaT
    else:
        return pd.NaT  # Si ce n'est pas une chaÃ®ne ou un Timestamp valide, retourner NaT

# Appliquer la fonction Ã  la colonne 'Date'
df['Date'] = df['Date'].apply(parse_date)

# CrÃ©er une liste vide pour stocker les donnÃ©es
data = []

# Exemple : Parcourir chaque ligne et rÃ©cupÃ©rer les auteurs et les dates
for _, row in df.iterrows():
    auteurs_split = row['Auteurs'].split(',')  # SÃ©parer les auteurs (assumÃ© format "Nom, PrÃ©nom")
    for i in range(0, len(auteurs_split), 2):  # Nom et PrÃ©nom alternent
        prenom = auteurs_split[i].strip()
        nom = auteurs_split[i+1].strip() if i + 1 < len(auteurs_split) else ""
        auteur = f"{nom} {prenom}"
        date = row['Date']
        data.append([auteur, date])

# Convertir en DataFrame
df_auteurs = pd.DataFrame(data, columns=['Auteur', 'Date'])

# Groupement par Auteur et Date pour compter les occurrences par auteur et par date
df_grouped = df_auteurs.groupby(['Auteur', 'Date']).size().reset_index(name='Nombre de publications')

# Calculer le nombre cumulatif de publications par auteur
df_grouped['Nombre de publications cumulÃ©es'] = df_grouped.groupby('Auteur')['Nombre de publications'].cumsum()

# Trouver les 10 auteurs les plus frÃ©quents en fonction du nombre total de publications
top_10_auteurs = df_grouped.groupby('Auteur')['Nombre de publications'].sum().nlargest(10).index

# Filtrer les donnÃ©es pour ne conserver que les 10 auteurs les plus frÃ©quents
df_top_10 = df_grouped[df_grouped['Auteur'].isin(top_10_auteurs)]
st.title("Analyse de l'Ã©volution cumulÃ©e des publications selon les auteurs")
# Ajouter une barre de dÃ©filement pour choisir le nombre d'auteurs
number_of_authors = st.slider(
    "SÃ©lectionner le nombre d'auteurs",
    min_value=1,
    max_value=7,  # Ajustez selon vos besoins
    value=5  # Valeur par dÃ©faut
)

# Trouver les auteurs les plus frÃ©quents en fonction du nombre sÃ©lectionnÃ©
top_auteurs_limit = df_grouped.groupby('Auteur')['Nombre de publications'].sum().nlargest(number_of_authors).index

# Filtrer les donnÃ©es en fonction du nombre d'auteurs sÃ©lectionnÃ©s
df_selected_authors = df_grouped[df_grouped['Auteur'].isin(top_auteurs_limit)]

# CrÃ©er un graphique avec Plotly pour l'Ã©volution cumulÃ©e des publications par auteur au fil du temps
fig = px.line(
    df_selected_authors, 
    x="Date",  # Utiliser la date pour l'axe X
    y="Nombre de publications cumulÃ©es",  # Nombre de publications cumulÃ©es pour l'axe Y
    color="Auteur",  # SÃ©parer par auteur
    title="Ã‰volution cumulÃ©e des publications des auteurs au fil du temps",
    labels={'Date': 'Date', 'Nombre de publications cumulÃ©es': 'Nombre de publications cumulÃ©es'}
)

# Personnalisation des axes
fig.update_xaxes(
    tickformat="%Y-%m-%d",  # Afficher les dates au format AAAA-MM-JJ
    title="Date"
)

# Afficher le graphique
st.plotly_chart(fig)






import pandas as pd
import plotly.express as px
import streamlit as st

# DÃ©finir la fonction pour analyser les dates
def parse_date(date_str):
    if pd.isna(date_str):  # Si la valeur est NaN (NaT), la laisser telle quelle
        return pd.NaT
    
    # Si la valeur est dÃ©jÃ  un Timestamp (datetime), la laisser telle quelle
    if isinstance(date_str, pd.Timestamp):
        return date_str
    
    # VÃ©rifier si la date est une chaÃ®ne de caractÃ¨res avant de tenter de la traiter
    if isinstance(date_str, str):
        if len(date_str) == 4 and date_str.isdigit():  # Cas de l'annÃ©e seule
            return pd.to_datetime(date_str + "-01-01")
        
        # Si la date est au format annÃ©e-mois (exemple "2020-11"), ajouter le 1er jour du mois
        if len(date_str) == 7 and date_str[4] == '-' and date_str[:4].isdigit() and date_str[5:].isdigit():
            return pd.to_datetime(date_str + "-01")
        
        # Si la date est dÃ©jÃ  complÃ¨te (exemple "05/07/2022"), tenter de la convertir
        try:
            return pd.to_datetime(date_str, dayfirst=True)
        except:
            return pd.NaT  # Si la conversion Ã©choue, renvoyer NaT
    else:
        return pd.NaT  # Si ce n'est pas une chaÃ®ne ou un Timestamp valide, retourner NaT

# Appliquer la fonction Ã  la colonne 'Date'
df['Date'] = df['Date'].apply(parse_date)

# CrÃ©er une liste vide pour stocker les donnÃ©es
data = []

# Exemple : Parcourir chaque ligne et rÃ©cupÃ©rer les lieux et les dates
for _, row in df.iterrows():
    lieux_split = row['Lieu'].split(',')  # SÃ©parer les lieux (assumÃ© format "Lieu1, Lieu2, ...")
    for lieu in lieux_split:  # Parcourir chaque lieu sÃ©parÃ©
        lieu = lieu.strip()  # Nettoyer l'espace
        date = row['Date']
        data.append([lieu, date])

# Convertir en DataFrame
df_lieux = pd.DataFrame(data, columns=['Lieu', 'Date'])

# Groupement par Lieu et Date pour compter les occurrences par lieu et par date
df_grouped = df_lieux.groupby(['Lieu', 'Date']).size().reset_index(name='Nombre de publications')

# Calculer le nombre cumulatif de publications par lieu
df_grouped['Nombre de publications cumulÃ©es'] = df_grouped.groupby('Lieu')['Nombre de publications'].cumsum()

# Trouver les 10 lieux les plus frÃ©quents en fonction du nombre total de publications
top_10_lieux = df_grouped.groupby('Lieu')['Nombre de publications'].sum().nlargest(10).index

# Filtrer les donnÃ©es pour ne conserver que les 10 lieux les plus frÃ©quents
df_top_10 = df_grouped[df_grouped['Lieu'].isin(top_10_lieux)]

# Titre de la section avec Streamlit
st.title("Analyse de l'Ã©volution cumulÃ©e des publications selon les lieux")

# Ajouter une barre de dÃ©filement pour choisir le nombre de lieux
number_of_places = st.slider(
    "SÃ©lectionner le nombre de lieux",
    min_value=1,
    max_value=7,  # Ajustez selon vos besoins
    value=5  # Valeur par dÃ©faut
)

# Trouver les lieux les plus frÃ©quents en fonction du nombre sÃ©lectionnÃ©
top_lieux_limit = df_grouped.groupby('Lieu')['Nombre de publications'].sum().nlargest(number_of_places).index

# Filtrer les donnÃ©es en fonction du nombre de lieux sÃ©lectionnÃ©s
df_selected_places = df_grouped[df_grouped['Lieu'].isin(top_lieux_limit)]

# CrÃ©er un graphique avec Plotly pour l'Ã©volution cumulÃ©e des publications par lieu au fil du temps
fig = px.line(
    df_selected_places, 
    x="Date",  # Utiliser la date pour l'axe X
    y="Nombre de publications cumulÃ©es",  # Nombre de publications cumulÃ©es pour l'axe Y
    color="Lieu",  # SÃ©parer par lieu
    title="Ã‰volution cumulÃ©e des publications des lieux au fil du temps",
    labels={'Date': 'Date', 'Nombre de publications cumulÃ©es': 'Nombre de publications cumulÃ©es'},
    width=5000,  # Largeur du graphique
    height=450   # Hauteur du graphique
)

# Personnalisation des axes
fig.update_xaxes(
    tickformat="%Y-%m-%d",  # Afficher les dates au format AAAA-MM-JJ
    title="Date"
)

# Afficher le graphique
st.plotly_chart(fig)

if st.button("â¬…ï¸ Retour Ã  l'accueil"):
    st.switch_page("Application.py")



